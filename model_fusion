import torch
import torch.nn as nn
import math
from torch.utils.data import DataLoader, Dataset
import os
import numpy as np
from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit
import time
import torch.optim as optim
class Conv2dWithConstraint(nn.Conv2d):
    def __init__(self, *args, max_norm=1, **kwargs):
        super(Conv2dWithConstraint, self).__init__(*args, **kwargs)
        self.max_norm = max_norm

    def forward(self, x):
        self.weight.data = torch.renorm(
            self.weight.data, p=2, dim=0, maxnorm=self.max_norm
        )
        # self.bias.data = self.bias.data.to(device)
        return super(Conv2dWithConstraint, self).forward(x)


class SELayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)


class CALayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(CALayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()

        )

    def forward(self, x):
        x = x.view(x.size(0),x.size(2),x.size(1),x.size(3))
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        output = x * y.expand_as(x)
        output = output.view(x.size(0),x.size(2),x.size(1),x.size(3))
        return output


class ADFCNN(nn.Module):
    def __init__(self,
                 num_channels: int,
                 sampling_rate: int,
                 F1=8, D=2, F2='auto', P1=4, P2=8, pool_mode='mean',
                 drop_out=0.25, layer_scale_init_value=1e-6, nums=2):
        super(ADFCNN, self).__init__()

        pooling_layer = dict(max=nn.MaxPool2d, mean=nn.AvgPool2d)[pool_mode]

        pooling_size = 0.3
        hop_size = 0.7

        if F2 == 'auto':
            F2 = F1 * D

        # Spectral
        self.spectral_1 = nn.Sequential(
            Conv2dWithConstraint(1, F1, kernel_size=[1, 100], padding='same', max_norm=2.),

            nn.BatchNorm2d(F1),
            # nn.ELU()
        )
        self.spectral_2 = nn.Sequential(
            Conv2dWithConstraint(1, F1, kernel_size=[1, 30], padding='same', max_norm=2.),

            nn.BatchNorm2d(F1),
            # nn.ELU()
        )

        # attention
        self.atten = nn.Sequential(
            nn.BatchNorm2d(F2),
            SELayer(F2),
            CALayer(30)
        )

        self.spatial = nn.Sequential(
            Conv2dWithConstraint(F2, F2, kernel_size=[num_channels, 1], padding='valid', max_norm=1.),
            nn.BatchNorm2d(F2),
            nn.ELU(),
            nn.Conv2d(F2, F2, kernel_size=[1, 1], padding='valid'),
            pooling_layer((1, 75), stride=(1, 25)),
            nn.Dropout(drop_out)
        )


    def forward(self, x):
        x_1 = self.spectral_1(x)
        x_2 = self.spectral_2(x)
        y = torch.cat((x_1, x_2), 1)
        # y = x_2
        identity = y
        y = self.atten(y)
        out = identity+y
        # out = y
        out = self.spatial(out)
        # print(out.shape)

        return out

class MaxNormConstraint(object):
    def __init__(self, max_value, axis=0):
        self.max_value = max_value
        self.axis = axis

    def __call__(self, w):
        return torch.clamp(w, max=self.max_value)

class classifier(nn.Module):
    def __init__(self, num_classes):
        super(classifier, self).__init__()
        self.linear1 = nn.Linear(176*2, 2)
        # self.linear2 = nn.Linear(128, 2)
        self.max_norm_constraint = MaxNormConstraint(0.5)

    def forward(self, x):
        x = x.view(x.size(0),-1)
        x = self.linear1(x)
        # x = self.linear2(x)
        return x


class Net(nn.Module):
    def __init__(self,
                 num_classes: 2,
                 num_channels: int,
                 sampling_rate: int):
        super(Net, self).__init__()

        self.backbone = ADFCNN(num_channels=num_channels, sampling_rate=sampling_rate)

        self.classifier = classifier(num_classes)

    def forward(self, x):
        x = self.backbone(x)
        # print(x.shape)
        x = self.classifier(x)
        return x

class DWSConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size):
        super(DWSConv, self).__init__()
        self.depth_conv = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=1, padding=0, groups=in_channels)
        self.point_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, groups=1)

    def forward(self, input):
        x = self.depth_conv(input)
        x = self.point_conv(x)
        return x

class fNIRSNet(nn.Module):
    def __init__(self, num_class, DHRConv_width=30, DWConv_height=72, num_DHRConv=8, num_DWConv=16):
        super(fNIRSNet, self).__init__()
        # DHR Module
        self.conv1 = DWSConv(in_channels=num_DHRConv, out_channels=num_DWConv, kernel_size=(1, DHRConv_width))
        self.bn1 = nn.BatchNorm2d(num_DWConv)

        # Global Module
        self.conv2 = nn.Conv2d(in_channels=1, out_channels=num_DHRConv, kernel_size=(DWConv_height, 1), stride=1, padding=0)
        self.bn2 = nn.BatchNorm2d(num_DHRConv)

        self.fc = nn.Linear(16, 2)
        self.max_norm_constraint = MaxNormConstraint(0.5)
        self.act = nn.Sigmoid()

        self.gru = nn.GRU(num_DHRConv,num_DWConv,2,batch_first = True)


    def forward(self, x):
        x = self.act(self.bn2(self.conv2(x)))
        identity = x
        x = self.act(self.bn1(self.conv1(x)))
        x = x.view(x.size()[0], -1)

        h0 = torch.zeros(2, identity.size(0), 16).to(x.device)
        y = identity.view(identity.size(0), -1, identity.size(1))
        y, _ = self.gru(y, h0)
        y = y[:, -1, :]
        # out = torch.cat((x, y), 1)
        out = x + y
        out = self.fc(out)
        return out

class DDEF(nn.Module):
    def __init__(self,num_classes=2):
        super(DDEF, self).__init__()
        self.eegnet = Net(num_classes=2,sampling_rate=200,num_channels=30)
        self.fnirsnet = fNIRSNet(num_class=2)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self,input1,input2,class_nums=2):
        # modal 1
        x1 = self.eegnet(input1)
        x1 = x1.view(x1.size()[0], -1)
#         x1 = self.linear1(x1)
        e1 = self.relu(x1)
        b12 = self.sigmoid(x1)

        alpha11 = e1 + 1
        S1 = torch.sum(alpha11,dim=1).unsqueeze(dim=1)

        b11 = e1 / S1
        u1 = class_nums / S1

        # DST fusion for two BBAs
        b1 = b11 * b12 + u1 * b12
        kappa1 = torch.sum(b1,dim=1).unsqueeze(dim=1)
        b_new1 = (1 - u1) * b1 / kappa1
        alpha_new1 = S1 * b_new1 + 1

        # modal 2
        x2 = self.fnirsnet(input2)
        x2 = x2.view(x2.size()[0],-1)
        e2 = self.relu(x2)
        b22 = self.sigmoid(x2)

        alpha21 = e2 + 1
        S2 = torch.sum(alpha21,dim=1).unsqueeze(dim=1)
        b21 = e2 / S2
        u2 = class_nums/S2
        # DST fusion for two BBAs
        b2 = b21*b22+u2*b22
        kappa2 = torch.sum(b2,dim=1).unsqueeze(dim=1)
        b_new2 = (1-u2)*b2/kappa2
        alpha_new2 = S2*b_new2+1

        ############# DST fusion for two modalities

        b = b_new1*b_new2 + b_new1*u2 + b_new2*u1
        u = u1*u2
        kappa = torch.sum(b,dim=1).unsqueeze(dim=1)+u
        # print(kappa.shape)
        b_new = b/kappa
        u_new = u/kappa
        S = class_nums/u_new
        alpha_new = S*b_new+1
        return alpha_new
